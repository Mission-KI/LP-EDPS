import re
import shutil
from datetime import datetime
from logging import Logger
from pathlib import Path
from tempfile import TemporaryDirectory

from pydantic import HttpUrl, ValidationError

from edps import Service
from edps.compression.zip import ZipAlgorithm
from edps.context import OutputLocalFilesContext
from edps.task import SimpleTaskContext
from edps.types import Config, DataSpace, License, Publisher, UserProvidedEdpData
from pontusx.args import Args
from pontusx.metadata import DDO, read_custom_data_file, read_ddo_file

PONTUSX_DS_NAME = "Pontus-X"
PONTUSX_DS_URL = "https://portal.pontus-x.eu"
PONTUSX_ASSET_BASE_URL = f"{PONTUSX_DS_URL}/asset"


def to_user_provided_edp_data(ddo: DDO) -> UserProvidedEdpData:
    publishDate = ddo.metadata.updated or ddo.metadata.created or datetime.now()

    try:
        license = License(url=str(HttpUrl(ddo.metadata.license)))
    except ValidationError:
        license = License(name=ddo.metadata.license)

    return UserProvidedEdpData(
        assetId=ddo.id,
        name=ddo.metadata.name,
        description=ddo.metadata.description,
        tags=ddo.metadata.tags,
        url=f"{PONTUSX_ASSET_BASE_URL}/{ddo.id}",
        dataSpace=DataSpace(
            name=PONTUSX_DS_NAME,
            url=PONTUSX_DS_URL,
        ),
        publisher=Publisher(
            name=ddo.metadata.author,
        ),
        publishDate=publishDate,
        license=license,
        freely_available=False,
    )


def identify_file_extension(logger: Logger, args: Args):
    try:
        custom_data = read_custom_data_file(args.custom_data_file)
        file_extension = custom_data.fileInfo.fileExtension
        logger.info("File extension according to custom data file: %s", file_extension)
    except FileNotFoundError:
        # TODO Catch error about a missing custom data file but only until this file is generated by Pontux-X!
        logger.warning("Custom data file is missing, assuming 'csv' file extension...")
        file_extension = "csv"
    return file_extension


def sanitize_file_part(file_part: str) -> str:
    # Keep only alphanumeric characters and -_
    return re.sub(r"[^a-zA-Z0-9-_]", "", file_part)


async def run_service(logger: Logger, args: Args):
    ddo = read_ddo_file(args.ddo_file)
    logger.debug("DDO: %s", ddo)
    user_edp_data = to_user_provided_edp_data(ddo)
    logger.debug("UserProvidedEdpData: %s", user_edp_data)
    file_extension = identify_file_extension(logger, args)

    file_extension = sanitize_file_part(file_extension)
    input_filename = f"data.{file_extension}"
    with (
        TemporaryDirectory() as temp_working_dir_path,
        TemporaryDirectory() as temp_output_dir_path,
    ):
        output_dir = Path(temp_output_dir_path)
        logger.debug("Processing into output dir %s", output_dir)
        output_context = OutputLocalFilesContext(output_dir)

        ctx = SimpleTaskContext(logger, Path(temp_working_dir_path), output_context)

        ctx.input_path.mkdir(parents=True, exist_ok=True)
        shutil.copy(args.raw_data_file, ctx.input_path / input_filename)

        logger.info("Processing asset..")
        edps_config = Config(userProvidedEdpData=user_edp_data)
        await Service().analyse_asset(ctx, edps_config)

        logger.info("Zipping EDP..")
        target_archive = args.output_dir / f"{sanitize_file_part(user_edp_data.assetId)}.zip"
        await ZipAlgorithm().compress(output_dir, target_archive)
